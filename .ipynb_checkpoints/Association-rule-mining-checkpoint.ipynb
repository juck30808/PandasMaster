{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://annalyzin.files.wordpress.com/2016/04/association-rules-network-graph2.png\">\n",
    "\n",
    "<h6><center><a href=\"https://annalyzin.files.wordpress.com/2016/04/association-rules-network-graph2.png\">Source</a></center></h6>\n",
    "<h1><center>Associate Rule Mining</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents:**\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Overview: Dataset Description](#Overview)\n",
    "2. [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "    * [Individual Feature Visualisation](#Individual-Feature-Visualisation)\n",
    "    * [Multiple Feature Interaction Visualisation](#Multiple-Feature-Interactions-Visualisation)\n",
    "3. [Associate Rule Learning](#Associate-Rule-Learning)\n",
    "    * [Support](#Support)\n",
    "    * [Confidence](#Confidence)\n",
    "    * [Lift](#Lift)\n",
    "    * [Apriori](#Apriori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is an introduction in Association Rule Mining for the [Groceries dataset](https://www.kaggle.com/heeraldedhia/groceries-dataset) in python. We will first go through a brief Exploratory Data Analysis and then implement one of most popular Association Rule Learning Model. The aim of this dataset is to identify the association rules for the Market Basket Analysis. \n",
    "\n",
    "Association Rule Learning (or Associate Rule Mining) is a rule-based machine learning method to discover how items are associated to each other. Stores use them to figure out products that are bought together, this way they can provide different offers to the different customers e.g, buy one get one free. Earlier, recommendation systems like Amazon, Netflix used them.  In this notebook, we will go through Apriori type of Association Rule Learning model\n",
    "\n",
    "*We will be using `apyori` package from python to implement the apriori model.*\n",
    "\n",
    "Let’s get started!\n",
    "\n",
    "**Importing libraries and reading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # for data reading and manipulation\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import seaborn as sns # for visualization\n",
    "import numpy as np # for numerical computation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Member_number</th>\n",
       "      <th>Date</th>\n",
       "      <th>itemDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808</td>\n",
       "      <td>2015-07-21</td>\n",
       "      <td>tropical fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2552</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>whole milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2300</td>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>pip fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1187</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>other vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3037</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>whole milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Member_number       Date   itemDescription\n",
       "0           1808 2015-07-21    tropical fruit\n",
       "1           2552 2015-05-01        whole milk\n",
       "2           2300 2015-09-19         pip fruit\n",
       "3           1187 2015-12-12  other vegetables\n",
       "4           3037 2015-01-02        whole milk"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the groceries-dataset\n",
    "groceries = pd.read_csv('data/Groceries_dataset.csv', parse_dates=['Date'])\n",
    "groceries.head()\n",
    "#groceries.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Description**\n",
    "* Member_number: A unique id of each customer who bought groceries\n",
    "* Date: The date at which the customer bought the groceries\n",
    "* itemDescription: Description of the item that customer bought\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "In EDA, we will first start with individual feature analysis then we will explore multiple feature interactions.\n",
    "\n",
    "**Let's look at the time duration of the data we have given.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "print(\"We have the data from\",groceries.Date.min(),\"to\", groceries.Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# For extracting year,month and day to new column,follow the code:\n",
    "groceries['year'] = groceries['Date'].dt.year\n",
    "groceries['month'] = groceries['Date'].dt.month\n",
    "groceries['day'] = groceries['Date'].dt.day\n",
    "groceries['day_of_week'] = groceries['Date'].dt.day_name()\n",
    "groceries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Feature Visualisation\n",
    "\n",
    "We start by simply plotting the distributions of the each feature individually, before moving on to multi-feature visuals and correlations. Here, we’re dealing with the features one by one.\n",
    "\n",
    "Let's look at the customers' visiting rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [13, 7]\n",
    "\n",
    "color = plt.cm.spring(np.linspace(0, 1, 5))\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "groceries['Member_number'].value_counts().head().plot(kind='bar', color = color, ax=ax, title='Customers who visited the store more often');\n",
    "ax.set_xlabel(\"Customer ID\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "groceries['Member_number'].value_counts(ascending=True).head().plot(kind='bar', color = color, ax=ax2, title='Customers who visited the store less often');\n",
    "ax2.set_xlabel(\"Customer ID\")\n",
    "ax2.set_ylabel(\"Count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that:\n",
    "* Member number 3180 bought the highest number of groceries, followed by Member number 3050, 2051 and 3737.\n",
    "* A lot of customers visited the store twice (seem to be tourists).\n",
    "\n",
    "Let's look at the date at which customers visited the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [13, 7]\n",
    "\n",
    "color = plt.cm.winter(np.linspace(0, 1, 10))\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "groceries['Date'].value_counts().head().plot(kind='bar', color = color, ax=ax, title='Date at which the store got the highest number of visits');\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "groceries['Date'].value_counts(ascending=True).head().plot(kind='bar', color = color, ax=ax2, title='Date at which the store got the lowest number of visits');\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_ylabel(\"Count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that:\n",
    "* A large number of customers visited the store on 21st January 2015 followed by 21st July 2015\n",
    "* Few customers visited the store on 9th January 2015 followed by 16th March 2015 \n",
    "* Both the highest most visitors and least visitors are recorded in 2015\n",
    "\n",
    "Let's look at the total count of items bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [13, 7]\n",
    "color = plt.cm.twilight(np.linspace(0, 1, 10))\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "groceries['itemDescription'].value_counts().head().plot(kind='bar', color = color, ax=ax, title='Most often bought Groceries');\n",
    "ax.set_xlabel(\"Grocery items\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "groceries['itemDescription'].value_counts(ascending=True).head().plot(kind='bar', color = color, ax=ax2, title='Least bought Groceries');\n",
    "ax2.set_xlabel(\"Grocery items\")\n",
    "ax2.set_ylabel(\"Count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found:\n",
    "* Whole milk is the highest bought item followed by other vegetables and rolls/buns\n",
    "* Preservation products and kitchen utensils are the least bought. \n",
    "\n",
    "Let's look at the day of the month at which customers visited the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "color = plt.cm.ocean(np.linspace(0, 1, 31))\n",
    "\n",
    "groceries['day'].value_counts().plot(kind='bar', color=color, title='Groceries bought in each day of the month').set(xlabel='Day of the month', ylabel='Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that:\n",
    "* 28th is the day of the month where highest amount of items are bought\n",
    "* 31st is the day of the month where lowest amount of items are bought (maybe because at the end of the month people were short on budget.)\n",
    "\n",
    "Let's look at the groceries bought in each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.rcdefaults()\n",
    "plt.rcParams[\"figure.figsize\"] = [13, 7]\n",
    "color = plt.cm.autumn(np.linspace(0, 1, 12))\n",
    "\n",
    "groceries['month'].value_counts().plot(kind='bar', color=color, title='Groceries bought in each month').set(xlabel='Month', ylabel='Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that:\n",
    "* In August, the highest amount of items are purchased.\n",
    "* In September, the lowest amount of items are purchased.\n",
    "\n",
    "Let's look at the groceries bought in each Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.rcdefaults()\n",
    "plt.rcParams[\"figure.figsize\"] = [13, 7]\n",
    "\n",
    "groceries['year'].value_counts().plot(kind='bar', title='Groceries bought in each year').set(xlabel='Year', ylabel='Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that:\n",
    "* In 2015, highest number of customers visited the store.\n",
    "* Both 2015 and 2014 are really close in terms of customer visiting rate.\n",
    "\n",
    "Let's look at groceries bought in each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "groceries['day_of_week'].value_counts().head(15).plot.pie(figsize = (15, 8), explode = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1))\n",
    "\n",
    "plt.title('Groceries count on each day',fontsize = 20)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that:\n",
    "* The Customer Visiting Rate is equally distributed across all the days of week.\n",
    "\n",
    "## Multiple Feature Interactions Visualisation\n",
    "\n",
    "We started with looking at each individual feature, let's start looking at feature relations, we will first go through time series analysis to manipulate and visualize time series data. To make it easier, we will aggregate customer's data and items data into single dataframe with respect to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's aggregate the data with date to see more clearly which items are bought on which date\n",
    "# create a new dataframe and store unique visitors and unique bought items\n",
    "groceries_time = pd.DataFrame(groceries.groupby('Date')['itemDescription'].nunique().index)\n",
    "groceries_time['members_count'] = groceries.groupby('Date')['Member_number'].nunique().values\n",
    "groceries_time['items_count'] = groceries.groupby('Date')['itemDescription'].nunique().values\n",
    "groceries_time['items'] = groceries.groupby('Date')['itemDescription'].unique().values\n",
    "groceries_time.set_index('Date',inplace=True)\n",
    "groceries_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the data with Density plots to see where the mass of the data is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "\n",
    "sns.kdeplot(data = groceries_time['members_count'],shade=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's seems like data is uniformly distributed without any trend. Let's verify that using lineplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "groceries_time['members_count'].plot(figsize=(10, 5),title='Number of member visited with time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that store had a more or less steady increase in its stock price over the from January 2014 to the January 2016 window. Therefore, we will now use association rules to find pairs of items that are associated to each other.\n",
    "\n",
    "\n",
    "# Associate Rule Learning\n",
    "\n",
    "Association rule learning is a technique to discover how items are associated to each other. Association can be measured in three common ways.\n",
    "\n",
    "## Support\n",
    "\n",
    "It tell us about how popular an itemset is, as measured by the proportion of transactions in which an itemset appears. It is measured as follows:\n",
    "\n",
    "For Movie Recommendation, we calculate it as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "support(M) = \\frac{\\text{number of user watchlists containing M}}{\\text{total number of user watchlists}}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "wheras for Market Basket Optimization, we calculate it as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "support(I) = \\frac{\\text{number of transactions containing I}}{\\text{total number of transactions}}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "## Confidence\n",
    "\n",
    "It tell us about how likely item B is purchased when item A is purchased, expressed as {A -> B}. It is measured as follows:\n",
    "\n",
    "For Movie Recommendation, we calculate it as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "confidence(M_1\\rightarrow{M_2}) = \\frac{\\text{number of user watchlists containing $M_1$ and $M_2$}}{\\text{number of user watchlists containing $M_1$}}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "wheras for Market Basket Optimization, we calculate it as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "confidence(I_1\\rightarrow{I_2}) = \\frac{\\text{number of transactions containing $I_1$ and $I_2$}}{\\text{number of transactions containing $I_1$}}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "## Lift\n",
    "\n",
    "It tell us about how likely the item B is purchased when the item A is purchased while controlling for how popular item B is. It is measured as follows:\n",
    "\n",
    "For Movie Recommendation, we calculate it as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "lift(M_1\\rightarrow{M_2}) = \\frac{Confidence(M_1\\rightarrow{M_2})}{Support(M_2)}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "wheras for Market Basket Optimization, we calculate it as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "lift(I_1\\rightarrow{I_2}) = \\frac{Confidence(I_1\\rightarrow{I_2})}{Support(I_2)}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "## Apriori\n",
    "\n",
    "Apriori algorithm consist of:\n",
    "\n",
    "1. Step 1: Set a minimum support and confidence.\n",
    "2. Step 2: Take all the subsets in transactions having higher support than minimum support.\n",
    "3. Step 3: Take all the rules of these subsets having higher confidence than minimum confidence.\n",
    "4. Step 4: Sort the rules by decreasing lift.\n",
    "\n",
    "We will be using `apriori` function from `apyori` package to implement the apriori algorithm. It return all the different association measures (or the rules) such support, confidence and lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# importing the library\n",
    "try:\n",
    "    import apyori\n",
    "except:\n",
    "    !pip install apyori\n",
    "\n",
    "from apyori import apriori # for association rule learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "transactions = groceries_time['items'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the algorithm and transform the result into well organised pandas dataframe to see which item pairs are associated more or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "rules = apriori(transactions = transactions, min_support=0.00030, min_confidance=0.01, min_lift=3, min_length=2, max_length=2)\n",
    "#let's transform them into a list\n",
    "results = list(rules)\n",
    "\n",
    "def inspect(results):\n",
    "    '''\n",
    "    function to put the result in well organised pandas dataframe\n",
    "    '''\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
    "    supports    = [result[1] for result in results]\n",
    "    confidences = [result[2][0][2] for result in results]\n",
    "    lifts       = [result[2][0][3] for result in results]\n",
    "    return list(zip(lhs, rhs, supports, confidences, lifts))\n",
    "\n",
    "resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Item #1', 'Item #2', 'Support', 'Confidence', 'Lift'])\n",
    "resultsinDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort all the rules by decreasing lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsinDataFrame.nlargest(n=10, columns='Lift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the store, people bought liquer with preservation products, kitchen utensil with prosecco and preservation products with spices. The store should add deals with preservation products, kitchen utensil and frozen chicken to increase it sales. Thanks and I hope you enjoyed while reading it. Happy coding!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
