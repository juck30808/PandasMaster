{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Google Forms Data with Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second part of an article from [Practical Business Python](htp://pbpython.com) describing how to retrieve and analyze data from a Google Form.\n",
    "\n",
    "Please review [part 1](http://pbpython.com/pandas-google-forms-part1.html) for the details of how to set up authentication and get the data into the pandaqs dataframe.\n",
    "\n",
    "The full article corresponding to this notebook is [here](http://pbpython.com/pandas-google-forms-part2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in our standard imports as well as the authentication libraries we will need to get access to our form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gspread in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from gspread) (0.5.2)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from gspread) (2.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from oauth2client) (0.2.7)\n",
      "Collecting httplib2>=0.9.1\n",
      "  Using cached httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from oauth2client) (4.8)\n",
      "Requirement already satisfied: six>=1.6.1 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from oauth2client) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from oauth2client) (0.4.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (from httplib2>=0.9.1->oauth2client) (3.0.4)\n",
      "Installing collected packages: httplib2, oauth2client\n",
      "Successfully installed httplib2-0.20.4 oauth2client-4.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install oauth2client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SignedJwtAssertionCredentials' from 'oauth2client.client' (C:\\Users\\cti110016\\Anaconda3\\lib\\site-packages\\oauth2client\\client.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CTI110~1\\AppData\\Local\\Temp/ipykernel_25256/15832767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgspread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSignedJwtAssertionCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SignedJwtAssertionCredentials' from 'oauth2client.client' (C:\\Users\\cti110016\\Anaconda3\\lib\\site-packages\\oauth2client\\client.py)"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.client import SignedJwtAssertionCredentials\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Ipython display as well as graphing libraries. For this article, we will be using [seaborn](http://stanford.edu/~mwaskom/software/seaborn/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup authentication process to pull in the survey data stored in the Google Sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPE = [\"https://spreadsheets.google.com/feeds\"]\n",
    "SECRETS_FILE = \"Pbpython-key.json\"\n",
    "SPREADSHEET = \"PBPython User Survey (Responses)\"\n",
    "# Based on docs here - http://gspread.readthedocs.org/en/latest/oauth2.html\n",
    "# Load in the secret JSON key (must be a service account)\n",
    "json_key = json.load(open(SECRETS_FILE))\n",
    "# Authenticate using the signed key\n",
    "credentials = SignedJwtAssertionCredentials(json_key['client_email'],\n",
    "                                            json_key['private_key'], SCOPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open up the file and read all data in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.authorize(credentials)\n",
    "# Open up the workbook based on the spreadsheet name\n",
    "workbook = gc.open(SPREADSHEET)\n",
    "# Get the first sheet\n",
    "sheet = workbook.sheet1\n",
    "# Extract all data into a dataframe\n",
    "results = pd.DataFrame(sheet.get_all_records())\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some cleanup to make the data easier to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some minor cleanups on the data\n",
    "# Rename the columns to make it easier to manipulate\n",
    "# The data comes in through a dictionary so we can not assume order stays the\n",
    "# same so must name each column\n",
    "column_names = {'Timestamp': 'timestamp',\n",
    "                'What version of python would you like to see used for the examples on the site?': 'version',\n",
    "                'How useful is the content on practical business python?': 'useful',\n",
    "                'What suggestions do you have for future content?': 'suggestions',\n",
    "                'How frequently do you use the following tools? [Python]': 'freq-py',\n",
    "                'How frequently do you use the following tools? [SQL]': 'freq-sql',\n",
    "                'How frequently do you use the following tools? [R]': 'freq-r',\n",
    "                'How frequently do you use the following tools? [Javascript]': 'freq-js',\n",
    "                'How frequently do you use the following tools? [VBA]': 'freq-vba',\n",
    "                'How frequently do you use the following tools? [Ruby]': 'freq-ruby',\n",
    "                'Which OS do you use most frequently?': 'os',\n",
    "                'Which python distribution do you primarily use?': 'distro',\n",
    "                'How would you like to be notified about new articles on this site?': 'notify'\n",
    "                }\n",
    "results.rename(columns=column_names, inplace=True)\n",
    "results.timestamp = pd.to_datetime(results.timestamp)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a small number of free form comments. Let's strip those out and remove them from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = results[results.suggestions.str.len() > 0][\"suggestions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only a small number of comments, just print them out.\n",
    "However, if we had more comments and wanted to do more analysis we certainly good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in suggestions.iteritems():\n",
    "    display(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the suggestions. We won't use them any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(\"suggestions\", axis=1, inplace=True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Numeric columns, start with describe to see what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we only have 1, 2, 3 as options the numeric results aren't telling us that much. I am going to convert the number to more useful descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['useful'] = results['useful'].map({1: '1-low', 2: '2-medium', 3: '3-high'})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts give us an easy distribution view into the raw numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"version\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use normalize to see it by percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.os.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the numbers are useful, wouldn't it be nicer to visually show the results?\n",
    "\n",
    "Seaborn's [factorplot](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.factorplot.html) is helpful for showing this kind of categorical data.\n",
    "\n",
    "Because factorplot is so powerful, I'll build up step by step to show how it can be used for complex data analysis.\n",
    "\n",
    "First, look at number of users by OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(\"os\", data=results, palette=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to order the results using x_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(\"os\", x_order=[\"Linux\", \"Windows\", \"Mac\"], data=results, palette=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a similar plot on python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(\"version\", data=results, palette=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful but wouldn't it be better to compare with OS and preferred python version? This is where factorplot starts to show more versatility. The key component is to use hue to automatically slice the data by python version (in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(\"os\", hue=\"version\", x_order=[\"Linux\", \"Windows\", \"Mac\"], data=results, palette=\"Paired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because seaborn knows how to work with dataframes, we just need to pass in the column names for the various arguments and it will do the analysis and presentation.\n",
    "\n",
    "How about if we try to see if there is any relationship between how useful the site is and OS/Python choice? We can add the useful column into the plot using col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(\"version\", hue=\"os\", data=results, col=\"useful\", palette=\"Paired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can add a column, we can also add a row and seaborn takes care of the rest.\n",
    "\n",
    "In looking at the data, we have two different versions of winpython so clean that up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['distro'] = results['distro'].str.replace('WinPython', 'winpython')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the distros. Since there is some overlap with the distros and os, let's only look at a subset of distros. For instance, someone using winpython is not going to be using it on a Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['distro'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most meaningful data would be looking at the Anaconda and Official python.org binaries. Let's filter all of our data only on these two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_distro = results[results[\"distro\"].isin([\"Anaconda\", \"Official python.org binaries\"])]\n",
    "results_distro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do our factorplot with multiple columns and rows using row and col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(\"version\", hue=\"os\", data=results_distro, col=\"useful\", row=\"distro\", margin_titles=True, sharex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Responses over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that we have 55 results now. It would be interesting to see how those results came in over time. Using this method, we can very simply look at this by any time period we want.\n",
    "\n",
    "The seaborn's [timeseries](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.tsplot.html) supports this type of analysis and much more.\n",
    "\n",
    "For ease of calculating responses over time, add a count colum for each response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"count\"] = 1\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get totals over time, set our index to the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = results.set_index('timestamp')\n",
    "total_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas TimeGrouper to summarize the data by day and do a cumulative sum. We could easily do this for any time period too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_results = total_results.groupby(pd.TimeGrouper('D'))[\"count\"].count().cumsum()\n",
    "running_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To label the x-axis we need to define our time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = pd.Series(range(0,len(running_results)), name=\"Days\")\n",
    "sns.tsplot(running_results, value=\"Total Responses\", time=step, color=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Heatmaps and Clustermaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section of data to analyze is the frequency with which readers are using different technology. I am going to use a [heatmap](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.heatmap.html#seaborn.heatmap) to look for any interesting insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"freq-py\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to do is construct a single DataFrame with all the value_counts for the specific technology.\n",
    "First we will create a list containing each value count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = []\n",
    "for tech in [\"freq-py\", \"freq-sql\", \"freq-r\", \"freq-ruby\", \"freq-js\", \"freq-vba\"]:\n",
    "    all_counts.append(results[tech].value_counts())\n",
    "display(all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, concat the lists along axis=1.\n",
    "\n",
    "Fill in any nan values with 0 too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_usage = pd.concat(all_counts, keys=[\"Python\", \"SQL\", \"R\", \"Ruby\", \"javascript\", \"VBA\"], axis=1)\n",
    "tech_usage = tech_usage.fillna(0)\n",
    "tech_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a nice table but there are a few problems.\n",
    "\n",
    "First, we have one column with blank values that we don't want.\n",
    "\n",
    "Secondly, we would like to order from Daily -> Never. Use reindex to accomplish both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_usage = tech_usage.reindex([\"Daily\", \"A couple times a week\", \"Once a month\", \"Infrequently\", \"Never\"])\n",
    "tech_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in the correct table format, we can create a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tech_usage, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what does this tell us?\n",
    "\n",
    "Not surprisingly, most people use python very frequently.\n",
    "\n",
    "Additionally, it looks like very few survey takers are using Ruby or VBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variation of the heatmap is the [clustermap](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.clustermap.html#seaborn.clustermap). The main feature it does is that it tries to reorganize the data to more easily see relationships/clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(tech_usage, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At first glance, it may seem to be a repeat but you'll notice that the order of the axes are different.\n",
    "\n",
    "For instance, python and SQL are clusterd in the lower right with higher usage and Ruby and VBA have a cluster in the upper left with lower usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
